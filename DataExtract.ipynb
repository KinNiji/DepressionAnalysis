{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Config\n",
    "import Utils\n",
    "DATA_FILE_PATH = Config.DATA_FILE_PATH_CONTINUOUS_RAW\n",
    "OUTPUT_FILE_PATH = Config.DATA_FILE_PATH_CONTINUOUS_EXTRACTED\n",
    "BEGIN_TIME = str(Utils.timestr2timestamp(Config.BEGIN_TIME))\n",
    "END_TIME = str(Utils.timestr2timestamp(Config.END_TIME))\n",
    "EXTRACT_INFO_MINUTE = Config.EXTRACT_INFO['minute']\n",
    "BEGIN_TIME = Utils.timestr2time(Config.BEGIN_TIME)\n",
    "END_TIME = Utils.timestr2time(Config.END_TIME)\n",
    "\n",
    "LABEL_FILE_PATH_LIST = [Config.LABEL_FILE_PATH_BEFORE, Config.LABEL_FILE_PATH_AFTER]\n",
    "LABEL_FILE_PATH_EMA = Config.LABEL_FILE_PATH_EMA\n",
    "LABEL_FILE_PATH = Config.LABEL_FILE_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 抽取血氧、心率、运动的有效数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "continuousbloodoxygensaturation\n",
      "ex_id: 17, count: 7072\n",
      "ex_id: 58, count: 2751\n",
      "ex_id: 12, count: 2751\n",
      "ex_id: 6, count: 11835\n",
      "ex_id: 50, count: 279\n",
      "ex_id: 3, count: 2607\n",
      "ex_id: 47, count: 596\n",
      "ex_id: 32, count: 8044\n",
      "ex_id: 29, count: 818\n",
      "ex_id: 30, count: 639\n",
      "ex_id: 25, count: 1986\n",
      "ex_id: 54, count: 7806\n",
      "ex_id: 5, count: 850\n",
      "ex_id: 38, count: 942\n",
      "ex_id: 53, count: 213\n",
      "ex_id: 55, count: 2495\n",
      "ex_id: 57, count: 8995\n",
      "ex_id: 37, count: 7515\n",
      "ex_id: 34, count: 10428\n",
      "ex_id: 41, count: 7768\n",
      "ex_id: 31, count: 1676\n",
      "ex_id: 44, count: 4878\n",
      "ex_id: 48, count: 6482\n",
      "ex_id: 45, count: 5902\n",
      "ex_id: 15, count: 1011\n",
      "ex_id: 42, count: 1721\n",
      "ex_id: 1, count: 1567\n",
      "ex_id: 56, count: 936\n",
      "ex_id: 4, count: 5294\n",
      "ex_id: 14, count: 1324\n",
      "ex_id: 59, count: 2041\n",
      "ex_id: 23, count: 11143\n",
      "ex_id: 11, count: 2894\n",
      "ex_id: 52, count: 7040\n",
      "ex_id: 40, count: 1631\n",
      "ex_id: 8, count: 1\n",
      "ex_id: 21, count: 1582\n",
      "ex_id: 49, count: 5274\n",
      "ex_id: 10, count: 2376\n",
      "ex_id: 22, count: 201\n",
      "ex_id: 36, count: 2165\n",
      "ex_id: 28, count: 7118\n",
      "ex_id: 13, count: 8098\n",
      "ex_id: 27, count: 12028\n",
      "ex_id: 20, count: 100\n",
      "ex_id: 51, count: 479\n",
      "ex_id: 43, count: 1296\n",
      "ex_id: 46, count: 1035\n",
      "ex_id: 7, count: 10440\n",
      "ex_id: 33, count: 953\n",
      "ex_id: 35, count: 399\n",
      "ex_id: 16, count: 298\n",
      "ex_id: 39, count: 494\n",
      "ex_id: 19, count: 606\n",
      "ex_id: 26, count: 1502\n",
      "ex_id: 2, count: 447\n",
      "ex_id: 18, count: 135\n",
      "\n",
      "continuousheartrate\n",
      "ex_id: 58, count: 24159\n",
      "ex_id: 30, count: 18224\n",
      "ex_id: 14, count: 19417\n",
      "ex_id: 34, count: 32644\n",
      "ex_id: 47, count: 18480\n",
      "ex_id: 27, count: 36830\n",
      "ex_id: 23, count: 31520\n",
      "ex_id: 3, count: 18985\n",
      "ex_id: 20, count: 22550\n",
      "ex_id: 33, count: 10827\n",
      "ex_id: 11, count: 20333\n",
      "ex_id: 35, count: 3596\n",
      "ex_id: 46, count: 30211\n",
      "ex_id: 57, count: 29326\n",
      "ex_id: 15, count: 25012\n",
      "ex_id: 17, count: 29847\n",
      "ex_id: 12, count: 18219\n",
      "ex_id: 37, count: 33638\n",
      "ex_id: 13, count: 19865\n",
      "ex_id: 32, count: 28137\n",
      "ex_id: 31, count: 21908\n",
      "ex_id: 38, count: 14154\n",
      "ex_id: 36, count: 19241\n",
      "ex_id: 25, count: 16536\n",
      "ex_id: 1, count: 22891\n",
      "ex_id: 50, count: 7980\n",
      "ex_id: 29, count: 17909\n",
      "ex_id: 5, count: 25963\n",
      "ex_id: 40, count: 22375\n",
      "ex_id: 8, count: 509\n",
      "ex_id: 6, count: 38612\n",
      "ex_id: 42, count: 20110\n",
      "ex_id: 48, count: 24164\n",
      "ex_id: 10, count: 24223\n",
      "ex_id: 19, count: 24366\n",
      "ex_id: 39, count: 3057\n",
      "ex_id: 45, count: 24418\n",
      "ex_id: 43, count: 27951\n",
      "ex_id: 52, count: 29930\n",
      "ex_id: 21, count: 18066\n",
      "ex_id: 49, count: 17686\n",
      "ex_id: 02, count: 23\n",
      "ex_id: 54, count: 22404\n",
      "ex_id: 51, count: 25183\n",
      "ex_id: 56, count: 18561\n",
      "ex_id: 44, count: 25631\n",
      "ex_id: 59, count: 21739\n",
      "ex_id: 28, count: 25687\n",
      "ex_id: 41, count: 27868\n",
      "ex_id: 53, count: 11198\n",
      "ex_id: 7, count: 34906\n",
      "ex_id: 22, count: 18104\n",
      "ex_id: 55, count: 23789\n",
      "ex_id: 16, count: 15131\n",
      "ex_id: 2, count: 2668\n",
      "ex_id: 4, count: 23943\n",
      "ex_id: 18, count: 13204\n",
      "ex_id: 26, count: 11730\n",
      "ex_id: 9, count: 524\n",
      "\n",
      "dailyworkoutdetail\n",
      "ex_id: 10, count: 6704\n",
      "ex_id: 5, count: 5292\n",
      "ex_id: 54, count: 4311\n",
      "ex_id: 38, count: 3876\n",
      "ex_id: 55, count: 5204\n",
      "ex_id: 40, count: 5478\n",
      "ex_id: 25, count: 3224\n",
      "ex_id: 52, count: 4485\n",
      "ex_id: 37, count: 5736\n",
      "ex_id: 34, count: 4723\n",
      "ex_id: 22, count: 4429\n",
      "ex_id: 19, count: 2831\n",
      "ex_id: 36, count: 3074\n",
      "ex_id: 39, count: 1277\n",
      "ex_id: 7, count: 3869\n",
      "ex_id: 16, count: 3452\n",
      "ex_id: 21, count: 5953\n",
      "ex_id: 4, count: 8573\n",
      "ex_id: 26, count: 1977\n",
      "ex_id: 49, count: 4023\n",
      "ex_id: 27, count: 8636\n",
      "ex_id: 3, count: 5085\n",
      "ex_id: 23, count: 6560\n",
      "ex_id: 20, count: 2582\n",
      "ex_id: 11, count: 2766\n",
      "ex_id: 12, count: 5054\n",
      "ex_id: 6, count: 4969\n",
      "ex_id: 28, count: 5929\n",
      "ex_id: 48, count: 4539\n",
      "ex_id: 1, count: 5945\n",
      "ex_id: 59, count: 3953\n",
      "ex_id: 33, count: 3969\n",
      "ex_id: 46, count: 4130\n",
      "ex_id: 14, count: 4249\n",
      "ex_id: 57, count: 6532\n",
      "ex_id: 50, count: 3724\n",
      "ex_id: 13, count: 3711\n",
      "ex_id: 58, count: 3729\n",
      "ex_id: 18, count: 3281\n",
      "ex_id: 30, count: 4768\n",
      "ex_id: 17, count: 4797\n",
      "ex_id: 41, count: 5902\n",
      "ex_id: 32, count: 5657\n",
      "ex_id: 51, count: 5768\n",
      "ex_id: 42, count: 6036\n",
      "ex_id: 45, count: 3678\n",
      "ex_id: 15, count: 6336\n",
      "ex_id: 47, count: 1708\n",
      "ex_id: 31, count: 5552\n",
      "ex_id: 43, count: 3860\n",
      "ex_id: 44, count: 6277\n",
      "ex_id: 56, count: 4561\n",
      "ex_id: 29, count: 7888\n",
      "ex_id: 35, count: 950\n",
      "ex_id: 8, count: 328\n",
      "ex_id: 2, count: 950\n",
      "ex_id: 53, count: 1332\n",
      "ex_id: 9, count: 205\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for file_name, info in EXTRACT_INFO_MINUTE.items():\n",
    "    print(file_name)\n",
    "    df = pd.read_csv(\n",
    "        f\"{DATA_FILE_PATH}/{file_name}.csv\", encoding=\"utf-8\", dtype=str)[info['useful_cols']]\n",
    "    # 对时间进行筛选\n",
    "    df = df[(BEGIN_TIME <= df['recordtime']) & (df['recordtime'] < END_TIME)]\n",
    "    # 创建输出目录\n",
    "    try:\n",
    "        os.mkdir(f\"{OUTPUT_FILE_PATH}/{file_name}\")\n",
    "    except:\n",
    "        ...\n",
    "    ex_id_list = df['externalid'].unique()\n",
    "    # 遍历所有external_id\n",
    "    for ex_id in ex_id_list:\n",
    "        # 创建当前external_id的列表，用于储存有用数据\n",
    "        useful_data = []\n",
    "        # 筛选当前external_id的子表\n",
    "        df_ex = df[df['externalid'] == ex_id]\n",
    "        # 遍历子表中每一行的有用数据\n",
    "        for index, line in df_ex.iterrows():\n",
    "            extraceded_line = {}\n",
    "            extractor = EXTRACT_INFO_MINUTE[file_name]['processer']\n",
    "            useful = json.loads(line[extractor['col_name']].replace(\"'\", '\"'))\n",
    "            for i in range(len(extractor['df_col_name'])):\n",
    "                if len(extractor['df_col_path'][i]) == 1:\n",
    "                    extraceded_line[extractor['df_col_name'][i]] = useful.get(extractor['df_col_path'][i][0])\n",
    "                elif len(extractor['df_col_path'][i]) == 2:\n",
    "                    extraceded_line[extractor['df_col_name'][i]] = useful.get(extractor['df_col_path'][i][0]).get(extractor['df_col_path'][i][1])\n",
    "            extraceded_line['timestamp'] = line['recordtime']\n",
    "            useful_data.append(extraceded_line)\n",
    "        # 将初步筛选出有效信息的数据以external_id存储到文件\n",
    "        df_useful = pd.DataFrame(useful_data)\n",
    "        print(f'ex_id: {ex_id}, count: {len(useful_data)}')\n",
    "        df_useful.to_csv(f\"{OUTPUT_FILE_PATH}/{file_name}/{ex_id}.csv\", encoding=\"utf-8\", index=False)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 抽取RRI的有效数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recordtime</th>\n",
       "      <th>externalid</th>\n",
       "      <th>rriData</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1663240486000</td>\n",
       "      <td>1224</td>\n",
       "      <td>[{'rri': {'unit': 'ms', 'value': 1043}, 'sqi':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1663240546000</td>\n",
       "      <td>1224</td>\n",
       "      <td>[{'rri': {'unit': 'ms', 'value': 1268}, 'sqi':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1663240666000</td>\n",
       "      <td>1224</td>\n",
       "      <td>[{'rri': {'unit': 'ms', 'value': 1346}, 'sqi':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1663240847000</td>\n",
       "      <td>1224</td>\n",
       "      <td>[{'rri': {'unit': 'ms', 'value': 1887}, 'sqi':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1663240910000</td>\n",
       "      <td>1224</td>\n",
       "      <td>[{'rri': {'unit': 'ms', 'value': 617}, 'sqi': ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      recordtime externalid                                            rriData\n",
       "0  1663240486000       1224  [{'rri': {'unit': 'ms', 'value': 1043}, 'sqi':...\n",
       "1  1663240546000       1224  [{'rri': {'unit': 'ms', 'value': 1268}, 'sqi':...\n",
       "2  1663240666000       1224  [{'rri': {'unit': 'ms', 'value': 1346}, 'sqi':...\n",
       "3  1663240847000       1224  [{'rri': {'unit': 'ms', 'value': 1887}, 'sqi':...\n",
       "4  1663240910000       1224  [{'rri': {'unit': 'ms', 'value': 617}, 'sqi': ..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 采集颗粒度为秒的只有rri\n",
    "file_name = 'continuousrri'\n",
    "EXTRACT_INFO_RRI = Config.EXTRACT_INFO['second'][file_name]\n",
    "\n",
    "df = pd.read_csv(f\"{DATA_FILE_PATH}/{file_name}_part11.csv\", encoding=\"utf-8\", dtype=str)[EXTRACT_INFO_RRI['useful_cols']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ex_id: 54, count: 1410005\n",
      "ex_id: 45, count: 1351030\n",
      "ex_id: 10, count: 1575571\n",
      "ex_id: 31, count: 1521764\n",
      "ex_id: 40, count: 1554431\n",
      "ex_id: 29, count: 1158815\n",
      "ex_id: 22, count: 116032\n",
      "ex_id: 23, count: 1938705\n",
      "ex_id: 43, count: 544593\n",
      "ex_id: 21, count: 1432674\n",
      "ex_id: 46, count: 368717\n",
      "ex_id: 32, count: 1920643\n",
      "ex_id: 18, count: 2569\n",
      "ex_id: 58, count: 1519413\n",
      "ex_id: 57, count: 1967219\n",
      "ex_id: 42, count: 1217586\n",
      "ex_id: 55, count: 1739964\n",
      "ex_id: 48, count: 1521330\n",
      "ex_id: 44, count: 1764957\n",
      "ex_id: 3, count: 1350301\n",
      "ex_id: 4, count: 1212519\n",
      "ex_id: 52, count: 1594045\n",
      "ex_id: 59, count: 1367138\n",
      "ex_id: 14, count: 1278426\n",
      "ex_id: 1, count: 1631321\n",
      "ex_id: 27, count: 2450267\n",
      "ex_id: 41, count: 829148\n",
      "ex_id: 49, count: 984196\n",
      "ex_id: 34, count: 1957930\n",
      "ex_id: 15, count: 1681018\n",
      "ex_id: 35, count: 267623\n",
      "ex_id: 13, count: 1242617\n",
      "ex_id: 56, count: 1049494\n",
      "ex_id: 51, count: 342885\n",
      "ex_id: 16, count: 946853\n",
      "ex_id: 38, count: 962846\n",
      "ex_id: 2, count: 181596\n",
      "ex_id: 33, count: 774774\n",
      "ex_id: 28, count: 1338228\n",
      "ex_id: 36, count: 1050502\n",
      "ex_id: 20, count: 873\n",
      "ex_id: 6, count: 2389617\n",
      "ex_id: 50, count: 495787\n",
      "ex_id: 47, count: 471733\n",
      "ex_id: 25, count: 714773\n",
      "ex_id: 53, count: 151567\n",
      "ex_id: 11, count: 677263\n",
      "ex_id: 39, count: 100145\n",
      "ex_id: 7, count: 2150280\n",
      "ex_id: 12, count: 1330152\n",
      "ex_id: 19, count: 147115\n",
      "ex_id: 37, count: 1376418\n",
      "ex_id: 5, count: 495875\n",
      "ex_id: 17, count: 1409003\n",
      "ex_id: 30, count: 204219\n",
      "ex_id: 9, count: 35037\n",
      "ex_id: 8, count: 37626\n",
      "ex_id: 02, count: 710\n",
      "ex_id: 26, count: 437081\n"
     ]
    }
   ],
   "source": [
    "# 采集颗粒度为秒的只有rri\n",
    "file_name = 'continuousrri'\n",
    "EXTRACT_INFO_RRI = Config.EXTRACT_INFO['second'][file_name]\n",
    "\n",
    "df = pd.read_csv(f\"{DATA_FILE_PATH}/{file_name}.csv\", encoding=\"utf-8\", dtype=str)[EXTRACT_INFO_RRI['useful_cols']]\n",
    "# 对时间进行筛选\n",
    "df = df[(BEGIN_TIME <= df['recordtime']) & (df['recordtime'] < END_TIME)]\n",
    "# 创建输出目录\n",
    "try:\n",
    "    os.mkdir(f\"{OUTPUT_FILE_PATH}/{file_name}\")\n",
    "except:\n",
    "    ...\n",
    "\n",
    "ex_id_list = df['externalid'].unique()\n",
    "\n",
    "# 遍历所有external_id\n",
    "for ex_id in ex_id_list:\n",
    "    # 创建当前external_id的列表，用于储存rri\n",
    "    rri_data = []\n",
    "    # 筛选当前external_id的子表\n",
    "    df_ex = df[df['externalid'] == ex_id]\n",
    "    # 遍历子表中每一行的rri_data\n",
    "    for index, df_line in df_ex.iterrows():\n",
    "        rri_list = json.loads(df_line['rriData'].replace(\"'\", '\"'))\n",
    "        for rri in rri_list:\n",
    "            rri_data.append({\n",
    "                'rri': rri['rri']['value'], \n",
    "                'sqi': rri['sqi'], \n",
    "                # 'time': timestamp2time(rri['timeFrame']['timestamp'])})\n",
    "                'timestamp': rri['timeFrame']['timestamp']})\n",
    "    # 将初步筛选出有效信息的数据以external_id存储到文件\n",
    "    df_rri = pd.DataFrame(rri_data)\n",
    "    print(f'ex_id: {ex_id}, count: {len(rri_data)}')\n",
    "    df_rri.to_csv(f\"{OUTPUT_FILE_PATH}/{file_name}/{ex_id}.csv\", encoding=\"utf-8\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 抽取量表、EMA的有效数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = {\"手环编号\": int, \"抑郁得分\": int, \"焦虑得分\": int, \"压力得分\": int, \"失眠得分\": int, \"自杀得分\": int}\n",
    "[df_before, df_after] = [pd.read_excel(_, dtype=str).drop('创建时间', axis=1).astype(dtype).sort_values(by='手环编号') for _ in LABEL_FILE_PATH_LIST]\n",
    "df_before = df_before.rename(columns={'手环编号': 'external_id', '抑郁得分': 'PHQ9-1', '焦虑得分': 'GAD7-1', '压力得分': 'ISI-1', '失眠得分': 'PSS-1', '自杀得分': 'BSI-1'})\n",
    "df_after = df_after.rename(columns={'手环编号': 'external_id', '抑郁得分': 'PHQ9-2', '焦虑得分': 'GAD7-2', '压力得分': 'ISI-2', '失眠得分': 'PSS-2', '自杀得分': 'BSI-2'})\n",
    "df = pd.merge(df_before, df_after)\n",
    "df.to_csv(f\"{LABEL_FILE_PATH}/scale.csv\", encoding=\"utf-8\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = {\"external_id\": int, \"upload_time\": str}\n",
    "df_ema = pd.read_csv(LABEL_FILE_PATH_EMA, encoding=\"utf-8\", dtype=str).drop([\"no\", \"sleep_time\", \"awake_time\"], axis=1).astype(dtype).sort_values(by='external_id')\n",
    "df_ema['upload_time'] = pd.to_datetime(df_ema['upload_time'])\n",
    "df_ema = df_ema[(df_ema['upload_time'] >= BEGIN_TIME) & (df_ema['upload_time'] <= END_TIME)]\n",
    "df_ema = df_ema.sort_values(by=['external_id', 'upload_time'])\n",
    "df_ema.drop_duplicates(keep='first', inplace=True, ignore_index=True)\n",
    "df_ema['date'] = df_ema['upload_time'].dt.date\n",
    "df_ema['period'] = df_ema['upload_time'].dt.hour.apply(lambda x: 1 if x > 12 else 0)\n",
    "df_ema = df_ema.drop('upload_time', axis=1)\n",
    "df_ema.to_csv(f\"{LABEL_FILE_PATH}/ema.csv\", encoding=\"utf-8\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 统计数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['continuousbloodoxygensaturation',\n",
       " 'continuousheartrate',\n",
       " 'continuousrri',\n",
       " 'dailyworkoutdetail']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name_list = os.listdir(OUTPUT_FILE_PATH)\n",
    "for file_name in file_name_list:\n",
    "    ex_id_list = [int(_.split('.')[0]) for _ in os.listdir(f\"{DATA_FILE_PATH}/{file_name}\")]\n",
    "    ex_id_list.sort()\n",
    "    for ex_id in tqdm(ex_id_list):\n",
    "        df_data = pd.read_csv(f\"{DATA_FILE_PATH}/{file_name}/{ex_id}.csv\", encoding=\"utf-8\").drop('timestamp', axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
